{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdedc4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e9e8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### GET ACCESS TOKEN\n",
    "import requests\n",
    "\n",
    "def get_token():\n",
    "    client_id = 'bb55f61d0c724f28bbb265fcc110b1bb'\n",
    "    client_secret = '518f0ffd09724428b90254eaad8be47c'\n",
    "\n",
    "    auth_url = 'https://accounts.spotify.com/api/token'\n",
    "\n",
    "    data = {\n",
    "        'grant_type': 'client_credentials',\n",
    "        'client_id': client_id,\n",
    "        'client_secret': client_secret,\n",
    "    }\n",
    "    auth_response = requests.post(auth_url, data=data)\n",
    "    access_token = auth_response.json().get('access_token')\n",
    "    return access_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5239eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get files from directory\n",
    "\n",
    "files = []\n",
    "for file in os.listdir(\"spotify_million_playlist_dataset/data/\"):\n",
    "    if file.endswith(\".json\"):\n",
    "        files.append(file)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de0ffa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#move files into dataframe in sets of 5 uptil 100\n",
    "\n",
    "#default\n",
    "#file_slice_start = 0\n",
    "#file_slice_end = 5\n",
    "#file_counter = 0\n",
    "\n",
    "\n",
    "#added in because I messed up and did the first two sets of 5 differently\n",
    "file_slice_start = 10\n",
    "file_slice_end = 15\n",
    "file_counter = 1\n",
    "\n",
    "while file_slice_end <= 100:   \n",
    "    df = pd.DataFrame()\n",
    "    batch_of_files = files[file_slice_start:file_slice_end]\n",
    "    for file in tqdm(batch_of_files):\n",
    "        rows = []\n",
    "        filename = \"spotify_million_playlist_dataset/data/\" + file\n",
    "        f = open(filename)\n",
    "        data = json.load(f)\n",
    "        for playlist in data['playlists']:\n",
    "            for track in playlist['tracks']:\n",
    "                track.pop('artist_uri', None)\n",
    "                track.pop('album_uri', None)\n",
    "                track.pop('duration_ms', None)\n",
    "                track.pop('album_name', None)\n",
    "                track['playlist_pid'] = playlist['pid']\n",
    "                rows.append(track)\n",
    "\n",
    "        df = pd.concat([df, pd.DataFrame.from_dict(rows, orient='columns')])\n",
    "    \n",
    "    #for each batch run api call:\n",
    "    \n",
    "    #get new access token \n",
    "    access_token = get_token()\n",
    "    \n",
    "    #get song ids\n",
    "    ids = list(df['track_uri'].str.replace('spotify:track:', '').unique())\n",
    "    #turn into chunks of 100 ids each\n",
    "    list_chunks = generate_chunks(ids)\n",
    "    #turn each chunk into a string\n",
    "    list_string_chunks = generate_strings(list_chunks)\n",
    "    \n",
    "    #call api with list of strings\n",
    "    api_response = get_attributes(list_string_chunks, access_token)\n",
    "    #turn json response into a dataframe\n",
    "    attribute_df = create_df_attributes(api_response)\n",
    "    #join onto original dataframe, export\n",
    "    format_and_export(df, attribute_df, file_counter)\n",
    "    \n",
    "    file_slice_start = file_slice_start + 5\n",
    "    file_slice_end = file_slice_end + 5\n",
    "    file_counter = file_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecebc1e3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc1c477",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHUNK CREATOR FUNCTION###\n",
    "## given list of song ids, returns list of 100id lists\n",
    "\n",
    "#counter for # of chunks\n",
    "def generate_chunks(ids):\n",
    "    counter = 0\n",
    "\n",
    "    final_chunk_count = len(ids) % 100\n",
    "\n",
    "    #chunk # to stop at because next chunk will not have 100 entries\n",
    "    #will be 6829 in this case\n",
    "    stop_num = (int)((len(ids) - final_chunk_count) / 100)\n",
    "\n",
    "    #list to hold chunks\n",
    "    list_chunks = []\n",
    "\n",
    "    #chunks\n",
    "    slice_start = 0\n",
    "    slice_end = 100\n",
    "\n",
    "    #iteration over total ids\n",
    "    while counter < stop_num:\n",
    "        #temp list to be added to main chunk list\n",
    "        temp_list = ids[slice_start:slice_end]\n",
    "        list_chunks.append(temp_list)\n",
    "        #move indeces to alter slice\n",
    "        slice_start = slice_start + 100\n",
    "        slice_end = slice_end + 100\n",
    "        counter = counter + 1\n",
    "    list_chunks\n",
    "\n",
    "    final_chunk = ids[slice_end:slice_end+final_chunk_count]\n",
    "    list_chunks.append(final_chunk)\n",
    "    \n",
    "    return list_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763c6acb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### CHUNK STRING CREATOR FUNCTION ###\n",
    "### given list of 100id lists, returns list of *comma seperated 100songs strings*###\n",
    "\n",
    "def generate_strings(list_chunks):\n",
    "    list_string_chunks =[]\n",
    "\n",
    "    for chunk in list_chunks:\n",
    "        temp_string = ''\n",
    "        for song_id in chunk:\n",
    "            if song_id == chunk[0]:\n",
    "                temp_string = song_id\n",
    "            else:\n",
    "                temp_string = temp_string + ',' + song_id\n",
    "        list_string_chunks.append(temp_string)\n",
    "\n",
    "    return list_string_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df5f1b7",
   "metadata": {},
   "source": [
    "# API CALL : 20 Min each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632ac221",
   "metadata": {},
   "outputs": [],
   "source": [
    "###CALL TO WEB API###\n",
    "##given list of strings where each string is 100 song ids seperated by commas\n",
    "##returns responses in json format\n",
    "def get_attributes(list_string_chunks, access_token):\n",
    "    responses = []\n",
    "\n",
    "    counter = 0\n",
    "\n",
    "    #constant parts of the 'get' message\n",
    "    test_url = \"https://api.spotify.com/v1/audio-features/?ids=\"\n",
    "    test_header = {\n",
    "            'Authorization': 'Bearer ' + access_token\n",
    "        }\n",
    "\n",
    "    #iteration over chunks\n",
    "    for chunk_string in tqdm(list_string_chunks, desc='api_call...'):\n",
    "        if counter % 100 == 0:\n",
    "            time.sleep(35) \n",
    "        #cusotmized url\n",
    "        to_send_url = test_url + chunk_string\n",
    "\n",
    "        #get request\n",
    "        response = requests.get(to_send_url, headers=test_header)\n",
    "        if response.status_code == 200:\n",
    "            # Process the response data (in JSON format)\n",
    "            responses.append(response.json())\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code} - {response.text}\")\n",
    "            print(response.json)\n",
    "\n",
    "        counter = counter + 1\n",
    "\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1657f66",
   "metadata": {},
   "source": [
    "# FORMATTING RESPONSE and Making Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7bfbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "###CREATES DATAFRAME OF SONG ATTRIBUTES###\n",
    "\n",
    "def create_df_attributes(responses):\n",
    "    audio_feature_df = pd.DataFrame()\n",
    "    for response in tqdm(responses, desc='creating attribute dataframe'):\n",
    "        audio_for_chunk = response['audio_features']\n",
    "        rows = []\n",
    "        for entry in range(len(audio_for_chunk)):\n",
    "            if audio_for_chunk[entry] is not None:\n",
    "                rows.append(audio_for_chunk[entry])\n",
    "\n",
    "        audio_feature_df = pd.concat([audio_feature_df, pd.DataFrame.from_dict(rows, orient='columns')])\n",
    "\n",
    "    return audio_feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305583ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "### format and export ###\n",
    "def format_and_export(df, attribute_df,file_counter):\n",
    "    #join on key=track_uri\n",
    "    joined = df.join(attribute_df.set_index('uri'), on='track_uri')\n",
    "    joined.to_csv(\"generated_json/full_dataframe_pt\" + str(file_counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a40af8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/adic/Desktop/DS3000/spotifyDS300/generated_json/file_with_attributes.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e96e046",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['playlist_pid'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828622c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
